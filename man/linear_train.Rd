% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/linear_train.R
\name{linear_train}
\alias{linear_train}
\title{Train a Linear Regression Model for Prediction of Protein Function}
\usage{
linear_train(
  train_data,
  train_labels,
  valid_data,
  valid_labels,
  reg = "elastic",
  reg_hypers = setNames(c(0.01, 0.01), c("l1", "l2")),
  num_iter = 1000,
  rec_loss_every = 10,
  learning_rate = 0.01
)
}
\arguments{
\item{train_data}{Rank 3 array of encoded aligned protein sequences.}

\item{train_labels}{Numeric vector of labels for each of the given training
examples.}

\item{valid_data}{Rank 3 encoded array of aligned protein sequences.}

\item{valid_labels}{Numeric vector of labels for each of the given validation
examples.}

\item{reg}{c('elastic, ridge, lasso'), elastic by default. Specified the
regularization technique to be used. Appropriate regularization
hyperparameters must be defined.}

\item{reg_hypers}{Named numeric vector containing the l1 and l2 constants to
be used in regularization. Both 0.01 by default. NOTE: Ensure that l1 and l2
hyperparameters required for chosen regularisation are used.}

\item{num_iter}{The integer number of iterations to be performed during gradient
descent. 1000 by default. Higher values often lead to more performant models,
but can also lead to overfitting.}

\item{rec_loss_every}{Integer. The program will record the cost on the training set
every <rec_loss_every> iterations.}

\item{learning_rate}{The double learning rate for gradient descent.}
}
\value{
A trained model, containing interprtable weights that may be used for
prediction of further examples.
}
\description{
Trains a linear model using gradient descent. Stores the performance on the
training and validations sets throughout the process.
}
\examples{

examples <- rhoData$data
labels <- rhoData$labels

shuffled_datasets <- shuffled_partitions(examples, labels, 650,
                                         encode=encode_physchem)

model <- linear_train(train_data = shuffled_datasets$e1,
                      train_labels = shuffled_datasets$l1,
                      valid_data = shuffled_datasets$e2,
                      valid_labels = shuffled_datasets$l2,
                      reg = 'ridge',
                      reg_hypers = setNames(c(0.001, 0.001), c("l1", "l2")),
                      num_iter = 1000,
                      rec_loss_every = 100,
                      learning_rate = 0.001
                      )

predictions(shuffled_datasets$e1[50:100, ,], model)

}
